{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "SIBDL-demo-group-13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80ee6732725c407badb5276ac8a82548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61d108974f3b4982ba8fde78643acd1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_032e42d2a27942aa92682ac6d99f40cc",
              "IPY_MODEL_777a00d4b693429b86c5fe08c0e90ee1"
            ]
          }
        },
        "61d108974f3b4982ba8fde78643acd1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "032e42d2a27942aa92682ac6d99f40cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_618f101826dc4c31b5d1918d5c0abc10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_717234fd204d42b5b190631cdd436090"
          }
        },
        "777a00d4b693429b86c5fe08c0e90ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87c93b0df84c45b9b984b43a06135d50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 118/? [02:39&lt;00:00,  1.35s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_054acd48e8ab4554afaeb4bf1caa18de"
          }
        },
        "618f101826dc4c31b5d1918d5c0abc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "717234fd204d42b5b190631cdd436090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87c93b0df84c45b9b984b43a06135d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "054acd48e8ab4554afaeb4bf1caa18de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymohamedahmed/drbayes/blob/master/SIBDL_demo_group_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HFtcUoANXK"
      },
      "source": [
        "# Machine Learning Seminars - Subspace Inference for Bayesian Deep Learning - Demo\n",
        "\n",
        "*Reviewed by Chiara Campagnola, Yousuf Mohamed-Ahmed and Hannah Teufel*\n",
        "\n",
        "**Aims of this notebook**:\n",
        "- Empirically evaluate the effectiveness of the uncertainty estimates produced (this is not evaluated by the paper)\n",
        "- Evaluate the performance gains achieved by applying approximate inference techniques in subspaces *vs* in the full space\n",
        "- Compare the method proposed by the paper to non-neural network based approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtjBG4O5AU0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04c1d5f-1abc-4288-eb82-c79b188f89a4"
      },
      "source": [
        "!rm -rf drbayes\n",
        "!git clone https://github.com/ymohamedahmed/drbayes.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'drbayes'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 349 (delta 43), reused 51 (delta 22), pack-reused 261\u001b[K\n",
            "Receiving objects: 100% (349/349), 11.61 MiB | 25.68 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03E9eUMjAvMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c36b2c-4c3b-4691-a738-1d1e6e9c8c86"
      },
      "source": [
        "!pip install -e drbayes"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drbayes\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (1.19.5)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (0.8.2+cu101)\n",
            "Collecting gpytorch>=0.1.0rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/d0/96634a8ae84b08bd64709c1abd4f319a70f404967c598690bca8be143fb8/gpytorch-1.4.0.tar.gz (286kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (0.8.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (1.4.1)\n",
            "Requirement already satisfied: setuptools>=39.1.0 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (54.0.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (1.7.1+cu101)\n",
            "Requirement already satisfied: scikit_learn>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (0.22.2.post1)\n",
            "Collecting pyro-ppl==1.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4d/e45ff02364438ce8698ed70b1fbd9240f7c4f6e509fb90e9c04657f895b5/pyro_ppl-1.5.2-py3-none-any.whl (607kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614kB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.4.5 in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (2.4.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from subspace-inference==0.0) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->subspace-inference==0.0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->subspace-inference==0.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.2->subspace-inference==0.0) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->subspace-inference==0.0) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20.2->subspace-inference==0.0) (1.0.1)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/81/957ae78e6398460a7230b0eb9b8f1cb954c5e913e868e48d89324c68cec7/pyro_api-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.5.2->subspace-inference==0.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2.2->subspace-inference==0.0) (1.15.0)\n",
            "Building wheels for collected packages: gpytorch\n",
            "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpytorch: filename=gpytorch-1.4.0-py2.py3-none-any.whl size=477826 sha256=6a6d71d86d49ffe35bbca58b2bb017bda4bd47728af959513799b5d8faa7ad1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/f5/39/404e1875f841e8a999e94a7efa17f6ef900298be5452b63b0c\n",
            "Successfully built gpytorch\n",
            "Installing collected packages: gpytorch, pyro-api, pyro-ppl, subspace-inference\n",
            "  Running setup.py develop for subspace-inference\n",
            "Successfully installed gpytorch-1.4.0 pyro-api-0.1.2 pyro-ppl-1.5.2 subspace-inference\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTnpHtKDANXP"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import subspace_inference\n",
        "import subspace_inference.utils as utils\n",
        "from subspace_inference.posteriors import SWAG\n",
        "from subspace_inference import models, losses, utils\n",
        "from subspace_inference.models import MLP\n",
        "from subspace_inference.visualization import plot_predictive\n",
        "from subspace_inference.posteriors.proj_model import SubspaceModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.manual_seed(1)\n",
        "torch.cuda.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UwutCr-CoVz"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqOHeNvdANXS"
      },
      "source": [
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "train = datasets.QMNIST(root=\"../data\",train=True, download=True,\n",
        "                   transform=transform)\n",
        "test = datasets.QMNIST('../data', train=False,download=True,\n",
        "                   transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train,batch_size=512)\n",
        "test_loader = torch.utils.data.DataLoader(test,batch_size=512)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gchOCSV-ANXT"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcwPHp__H-cs"
      },
      "source": [
        "def train(model, loader, optimizer, criterion, lr_init=1e-2, epochs=3000, \n",
        "          swag_model=None, swag=False, swag_start=2000, swag_freq=50, swag_lr=1e-3,\n",
        "          print_freq=100):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        t = (epoch + 1) / swag_start if swag else (epoch + 1) / epochs\n",
        "        lr_ratio = swag_lr / lr_init if swag else 0.05\n",
        "        \n",
        "        if t <= 0.5:\n",
        "            factor = 1.0\n",
        "        elif t <= 0.9:\n",
        "            factor = 1.0 - (1.0 - lr_ratio) * (t - 0.5) / 0.4\n",
        "        else:\n",
        "            factor = lr_ratio\n",
        "\n",
        "        lr = factor * lr_init\n",
        "        utils.adjust_learning_rate(optimizer, lr)\n",
        "        \n",
        "        train_res = utils.train_epoch(loader, model, criterion, optimizer, cuda=False, regression=False)\n",
        "        if swag and epoch > swag_start:\n",
        "            swag_model.collect_model(model)\n",
        "        \n",
        "        if (epoch % print_freq == 0 or epoch == epochs - 1):\n",
        "            print('Epoch %d. LR: %g. Loss: %.4f' % (epoch, lr, train_res['loss']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "tzzvWuu7ItK5",
        "outputId": "035bf15e-6f48-430f-85f7-d3a67938a2fc"
      },
      "source": [
        "wd = 0.\n",
        "lr_init = 1e-2\n",
        "\n",
        "model_cfg = models.ToyRegNet\n",
        "criterion = losses.GaussianLikelihood(noise_var=1.)\n",
        "criterion = F.cross_entropy\n",
        "model_cfg.kwargs = {\"dimensions\":[20,20], \"output_dim\":10, \"input_dim\":28*28}\n",
        "model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
        "for i in range(2):\n",
        "    print(\"Training Model\", i)\n",
        "    swag_model = SWAG(model_cfg.base, subspace_type=\"pca\", *model_cfg.args, **model_cfg.kwargs, \n",
        "                  subspace_kwargs={\"max_rank\": 10, \"pca_rank\": 10})\n",
        "    model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_init, momentum=0.95, weight_decay=wd)\n",
        "    \n",
        "    train(model, train_loader, optimizer, criterion, lr_init, 3000, print_freq=1000, \n",
        "          swag=True, swag_model=swag_model, swag_start=2000, swag_freq=10, swag_lr=1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-651a57c06299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     train(model, train_loader, optimizer, criterion, lr_init, 3000, print_freq=1000, \n\u001b[0;32m---> 17\u001b[0;31m           swag=True, swag_model=swag_model, swag_start=2000, swag_freq=10, swag_lr=1e-2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-0ee200a47211>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, criterion, lr_init, epochs, swag_model, swag, swag_start, swag_freq, swag_lr, print_freq)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswag\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mswag_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mswag_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drbayes/subspace_inference/utils.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(loader, model, criterion, optimizer, cuda, regression, verbose, subset)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'RegNetBase' object has no attribute 'log_softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THx5CUJMDa5u"
      },
      "source": [
        "\n",
        "def pretrain_mlp(model, loss_function, max_epochs, train_loader):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  swag_model = SWAG(VanillaMLP, subspace_type=\"pca\",\n",
        "                  subspace_kwargs={\"max_rank\": 10, \"pca_rank\": 10},dims=[28*28,50,20,10])\n",
        "  for epoch in range(max_epochs):\n",
        "    total_loss = 0\n",
        "    for x,y in train_loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      out = model(x)\n",
        "      swag_model.collect_model(model)\n",
        "\n",
        "      loss = loss_function(out,y) \n",
        "      #if not(elbo) else loss_function(model,x,y)[0]\n",
        "      # total_loss += loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss}\")\n",
        "\n",
        "  return swag_model.get_space()\n",
        "\n",
        "def train_vi_model(model, loss_function, max_epochs, train_loader):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  for epoch in range(max_epochs):\n",
        "    total_loss = 0\n",
        "    for x,y in train_loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      out = model(x)\n",
        "      loss = loss_function(model,x,y)[0]\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss}\")\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raWEYW_IANXT"
      },
      "source": [
        "### Mean Field Variational Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyFkYb7MANXU"
      },
      "source": [
        "### Ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acED4SKvANXU"
      },
      "source": [
        "### Neural network + Bayesian Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw3J4TWtANXV"
      },
      "source": [
        "### _SIBDL_: PCA subspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhcN0Zwa9Khx"
      },
      "source": [
        "class VanillaMLP(nn.Module):\n",
        "  def __init__(self, dims):\n",
        "    super(VanillaMLP,self).__init__()\n",
        "    layers = [nn.Flatten()] + [lay for (x,y) in zip(dims[:-1],dims[1:]) for lay in [nn.Linear(x,y), nn.ReLU()] ]\n",
        "    layers.pop()\n",
        "    \n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsvlp-ia8cZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d718a913-14e7-4119-d67d-a91cc384d3ff"
      },
      "source": [
        "model = VanillaMLP([28*28,50,20,10])\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VanillaMLP(\n",
            "  (model): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=784, out_features=50, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=50, out_features=20, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=20, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ7DJHwhANXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9118db31-0574-4148-8bc6-b386b97ed628"
      },
      "source": [
        "model = VanillaMLP([28*28,50,20,10])\n",
        "model.to(device)\n",
        "space = pretrain_mlp(model, F.cross_entropy, 20, train_loader)\n",
        "torch.save(model.state_dict(), \"MLP.pt\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 0.3785310983657837\n",
            "Epoch: 10, loss: 0.09515810012817383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZCPBVTTANXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a67c77-5e87-405a-b571-ff599dce3a21"
      },
      "source": [
        "from subspace_inference.posteriors.vi_model import VIModel, ELBO\n",
        "import math\n",
        "def get_pca_space(space):\n",
        "    # swag_model = SWAG(model_cfg.base, subspace_type=\"pca\", *model_cfg.args, **model_cfg.kwargs, \n",
        "    #               subspace_kwargs={\"max_rank\": 10, \"pca_rank\": 10})\n",
        "    # print(torch.load(\"MLP.pt\").keys())\n",
        "    # swag_model.load_state_dict(torch.load(\"MLP.pt\"))#[\"state_dict\"])\n",
        "    # mean, _, cov_factor = swag_model.get_space()\n",
        "    mean, _, cov_factor = space\n",
        "    subspace = SubspaceModel(mean, cov_factor)\n",
        "    return subspace\n",
        "\n",
        "subspace = get_pca_space(space)\n",
        "init_sigma = 1.\n",
        "prior_sigma = 5.\n",
        "criterion = losses.GaussianLikelihood(noise_var=.05)\n",
        "criterion = losses.cross_entropy\n",
        "temperature = 1.\n",
        "\n",
        "vi_model = VIModel(\n",
        "    subspace=subspace,\n",
        "    init_inv_softplus_sigma=math.log(math.exp(init_sigma) - 1.0),\n",
        "    prior_log_sigma=math.log(prior_sigma),\n",
        "    base=VanillaMLP,\n",
        "    dims=[28*28,50,20,10]\n",
        ")\n",
        "\n",
        "elbo = ELBO(criterion, len(train_loader.dataset), temperature=temperature)\n",
        "vi_model.to(device)\n",
        "train_vi_model(vi_model, elbo, 30, train_loader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 0.14315642416477203\n",
            "Epoch: 10, loss: 0.01816697046160698\n",
            "Epoch: 20, loss: 0.041046857833862305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "80ee6732725c407badb5276ac8a82548",
            "61d108974f3b4982ba8fde78643acd1b",
            "032e42d2a27942aa92682ac6d99f40cc",
            "777a00d4b693429b86c5fe08c0e90ee1",
            "618f101826dc4c31b5d1918d5c0abc10",
            "717234fd204d42b5b190631cdd436090",
            "87c93b0df84c45b9b984b43a06135d50",
            "054acd48e8ab4554afaeb4bf1caa18de"
          ]
        },
        "id": "4xL5GWzfg6VW",
        "outputId": "04147497-8ca7-4a25-9b46-3e5e881cda0f"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "num_evals = 1000\n",
        "test_batch_size = 512\n",
        "preds = torch.zeros((len(test_loader.dataset), num_evals))\n",
        "print(len(test_loader.dataset))\n",
        "for n, (x,y) in tqdm(enumerate(test_loader)):\n",
        "  x = x.to(device)\n",
        "  for i in range(num_evals):\n",
        "    preds[n*test_batch_size:(n+1)*test_batch_size,i] = vi_model(x).argmax(axis=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80ee6732725c407badb5276ac8a82548",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si00FeGAkHkU",
        "outputId": "c24b0efa-25b5-4e0f-b753-fd329b358306"
      },
      "source": [
        "uncert = torch.std(torch.tensor(~torch.eq(preds.T, torch.mode(preds,dim=1)[0]),dtype=torch.float32),dim=0)\n",
        "acc = (1.0*torch.mode(preds,dim=1)[0].eq(test_loader.dataset.targets[:,0])).mean()\n",
        "acc"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9660)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "uJqi8iYgn04_",
        "outputId": "d2110b44-d233-42b7-dca1-35431f382ece"
      },
      "source": [
        "inds = (-1.*uncert).argsort()[:10]\n",
        "print(uncert[inds])\n",
        "print(inds)\n",
        "for im in test_loader.dataset.data[inds]:\n",
        "  plt.imshow(im, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-15eeb32edb9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muncert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muncert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'uncert' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4TxmtQbANXY"
      },
      "source": [
        "## _References_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZ8oHrcOANXY"
      },
      "source": [
        "- A very useful repository for a lot of Bayesian NN implementations: https://github.com/JavierAntoran/Bayesian-Neural-Networks\n",
        "- The code for the paper is found at https://github.com/wjmaddox/drbayes and specifically the following notebook was adapted for this demonstration (https://github.com/wjmaddox/drbayes/blob/master/experiments/synthetic_regression/visualizing_uncertainty.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxYdtvcTANXZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}